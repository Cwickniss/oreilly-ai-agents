{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import ScrapeWebsiteTool, FileWriterTool, TXTSearchTool\n",
    "import requests\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "import os\n",
    "from crewai_tools import TXTSearchTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RT7vCRFaDbL1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Read website content\n",
      "Artificial intelligence - Wikipedia\n",
      "Jump to content\n",
      "Main menu\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\t\tNavig\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the tool, potentially passing the session\n",
    "scrape_tool = ScrapeWebsiteTool(website_url='https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "\n",
    "# Extract the text\n",
    "text = scrape_tool.run()\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MiF3SyT1DeDg",
    "outputId": "bcbff437-224e-4310-968c-d5560af4d6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content successfully written to ai.txt\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tool\n",
    "file_writer_tool = FileWriterTool()\n",
    "\n",
    "# Write content to a file in a specified directory\n",
    "result = file_writer_tool._run(filename='ai.txt', content = text, directory = '', overwrite=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rRFl6gfqEN8p"
   },
   "outputs": [],
   "source": [
    "\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize the tool with a specific text file, so the agent can search within the given text file's content\n",
    "# uses chromadb to chunk and vectorize data\n",
    "search_tool = TXTSearchTool(txt='ai.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klRUsA9VEYR_",
    "outputId": "88f1d9e6-a0eb-45fc-b1c2-33cc77d2e157"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEducator\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mUnderstand the topic of Natural Language Processing and give the correct response\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEducator\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch a txt's content\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"search_query\\\": \\\"Natural Language Processing\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Relevant Content:\n",
      "Natural language processing (NLP)[50] allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[51]\n",
      "Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f] unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem[29]). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\n",
      "Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[52] transformers (a deep learning architecture using an attention mechanism),[53] and others.[54] In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text,[55][56] and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[57]\n",
      "Perception\n",
      "Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[58]\n",
      "The field includes speech recognition,[59] image classification,[60] facial recognition, object recognition,[61]object tracking,[62] and robotic perception.[63]\n",
      "Social intelligence\n",
      "Kismet, a robot head which was made in the 1990s; a machine that can recognize and simulate emotions[64]\n",
      "\n",
      "Artificial neural networks\n",
      "Machine learning\n",
      "vteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware\n",
      "Printed circuit board\n",
      "Peripheral\n",
      "Integrated circuit\n",
      "Very Large Scale Integration\n",
      "Systems on Chip (SoCs)\n",
      "Energy consumption (Green computing)\n",
      "Electronic design automation\n",
      "Hardware acceleration\n",
      "Processor\n",
      "Size / Form\n",
      "Computer systems organization\n",
      "Computer architecture\n",
      "Computational complexity\n",
      "Dependability\n",
      "Embedded system\n",
      "Real-time computing\n",
      "Networks\n",
      "Network architecture\n",
      "Network protocol\n",
      "Network components\n",
      "Network scheduler\n",
      "Network performance evaluation\n",
      "Network service\n",
      "Software organization\n",
      "Interpreter\n",
      "Middleware\n",
      "Virtual machine\n",
      "Operating system\n",
      "Software quality\n",
      "Software notations and tools\n",
      "Programming paradigm\n",
      "Programming language\n",
      "Compiler\n",
      "Domain-specific language\n",
      "Modeling language\n",
      "Software framework\n",
      "Integrated development environment\n",
      "Software configuration management\n",
      "Software library\n",
      "Software repository\n",
      "Software development\n",
      "Control variable\n",
      "Software development process\n",
      "Requirements analysis\n",
      "Software design\n",
      "Software construction\n",
      "Software deployment\n",
      "Software engineering\n",
      "Software maintenance\n",
      "Programming team\n",
      "Open-source model\n",
      "Theory of computation\n",
      "Model of computation\n",
      "Stochastic\n",
      "Formal language\n",
      "Automata theory\n",
      "Computability theory\n",
      "Computational complexity theory\n",
      "Logic\n",
      "Semantics\n",
      "Algorithms\n",
      "Algorithm design\n",
      "Analysis of algorithms\n",
      "Algorithmic efficiency\n",
      "Randomized algorithm\n",
      "Computational geometry\n",
      "Mathematics of computing\n",
      "Discrete mathematics\n",
      "Probability\n",
      "Statistics\n",
      "Mathematical software\n",
      "Information theory\n",
      "Mathematical analysis\n",
      "Numerical analysis\n",
      "Theoretical computer science\n",
      "Information systems\n",
      "Database management system\n",
      "Information storage systems\n",
      "Enterprise information system\n",
      "Social information systems\n",
      "Geographic information system\n",
      "Decision support system\n",
      "Process control system\n",
      "Multimedia information system\n",
      "Data mining\n",
      "Digital library\n",
      "Computing platform\n",
      "Digital marketing\n",
      "World Wide Web\n",
      "Information retrieval\n",
      "Security\n",
      "\n",
      "Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pretrained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\", although this can be reduced with RLHF and quality data. They are used in chatbots, which allow people to ask a question or request a task in simple text.[122][123]\n",
      "Current models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA.[124] Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.[125]\n",
      "Hardware and software\n",
      "Main articles: Programming languages for artificial intelligence and Hardware for artificial intelligence\n",
      "In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.[126] Specialized programming languages such as Prolog were used in early AI research,[127] but general-purpose programming languages like Python have become predominant.[128]\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEducator\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Natural language processing (NLP) allows programs to read, write, and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval, and question answering. Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\n",
      "\n",
      "Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\n",
      "\n",
      "Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pretrained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations,\" although this can be reduced with RLHF and quality data. They are used in chatbots, which allow people to ask a question or request a task in simple text.\n",
      "\n",
      "Current models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "data_analyst = Agent(\n",
    "    role='Educator',\n",
    "    goal=f'Based on the context provided, answer the question - What is Natural Language Processing?',\n",
    "    backstory='You are a data expert',\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    tools=[search_tool]\n",
    ")\n",
    "\n",
    "test_task = Task(\n",
    "    description=\"Understand the topic of Natural Language Processing and give the correct response\",\n",
    "    agent=data_analyst,\n",
    "    expected_output='Give a correct response'\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    tasks=[test_task],\n",
    "    process=Process.sequential,\n",
    ")\n",
    "\n",
    "output = crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQSl499hFNLI",
    "outputId": "f8643290-3ae8-453f-dadc-0f0b688ea0bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) allows programs to read, write, and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval, and question answering. Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\n",
      "\n",
      "Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\n",
      "\n",
      "Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pretrained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations,\" although this can be reduced with RLHF and quality data. They are used in chatbots, which allow people to ask a question or request a task in simple text.\n",
      "\n",
      "Current models and services include Gemini (formerly Bard), ChatGPT, Grok, Claude, Copilot, and LLaMA. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.\n"
     ]
    }
   ],
   "source": [
    "print(output.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17JllC9ZQKEd",
    "outputId": "f43c4b19-b10d-4437-dacc-a7663cf81671"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mUnderstand the topic of Natural Language Processing and give the correct response\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to delegate the task of understanding the topic of Natural Language Processing and providing the correct response to the Educator, as they are skilled in explaining complex topics in an understandable manner.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"task\\\": \\\"Understand the topic of Natural Language Processing and provide a correct response\\\", \\\"context\\\": \\\"I need a detailed explanation of Natural Language Processing and its key components, applications, and importance in today's technological landscape.\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "\n",
      "Error executing tool. coworker mentioned not found, it must be one of the following options:\n",
      "- calculator\n",
      "- educator\n",
      "\u001b[00m\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCalculator\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mUnderstand the topic of Natural Language Processing and provide a correct response\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCalculator\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Natural Language Processing (NLP) is an essential area of artificial intelligence that enables machines to understand and interact with human language. Through key components such as tokenization, morphological analysis, part-of-speech tagging, named entity recognition, parsing, sentiment analysis, machine translation, and speech technologies, NLP powers various applications like chatbots, search engines, social media monitoring, and content recommendations. Its importance is underscored by its ability to analyze vast amounts of data, facilitate real-time user interaction, and contribute to the advancement of automated systems, making it a cornerstone in today's technological advancements.\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: It seems there was an error in delegating the task to the Educator. I will delegate the task to the Calculator instead, as they might still be able to provide some insights into the topic.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"task\\\": \\\"Understand the topic of Natural Language Processing and provide a correct response\\\", \\\"context\\\": \\\"I need a detailed explanation of Natural Language Processing and its key components, applications, and importance in today's technological landscape.\\\", \\\"coworker\\\": \\\"Calculator\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Natural Language Processing (NLP) is an essential area of artificial intelligence that enables machines to understand and interact with human language. Through key components such as tokenization, morphological analysis, part-of-speech tagging, named entity recognition, parsing, sentiment analysis, machine translation, and speech technologies, NLP powers various applications like chatbots, search engines, social media monitoring, and content recommendations. Its importance is underscored by its ability to analyze vast amounts of data, facilitate real-time user interaction, and contribute to the advancement of automated systems, making it a cornerstone in today's technological advancements.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Natural Language Processing (NLP) is an essential area of artificial intelligence that enables machines to understand and interact with human language. Through key components such as tokenization, morphological analysis, part-of-speech tagging, named entity recognition, parsing, sentiment analysis, machine translation, and speech technologies, NLP powers various applications like chatbots, search engines, social media monitoring, and content recommendations. Its importance is underscored by its ability to analyze vast amounts of data, facilitate real-time user interaction, and contribute to the advancement of automated systems, making it a cornerstone in today's technological advancements.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mTell me what 123 * 34 is\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mCrew Manager\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The result of 123 multiplied by 34 is 4182.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "test_task = Task(\n",
    "    description=\"Understand the topic of Natural Language Processing and give the correct response\",\n",
    "    # agent=data_analyst,  # commenting out the agent now, letting the manager decide\n",
    "    expected_output='Give a correct response'\n",
    ")\n",
    "calculator_agent = Agent(\n",
    "    role='Calculator',\n",
    "    goal=f'You calculate things',\n",
    "    backstory='You love math',\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    tools=[]\n",
    ")\n",
    "\n",
    "math_task = Task(\n",
    "    description=\"Tell me what 123 * 34 is\",\n",
    "    expected_output='Calculate this'\n",
    ")\n",
    "\n",
    "\n",
    "crew = Crew(\n",
    "    tasks=[math_task, test_task],\n",
    "    agents=[calculator_agent, data_analyst],\n",
    "    process=Process.hierarchical,\n",
    "    manager_llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "output = crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2BBfIw4SQwp",
    "outputId": "9fddc36b-a2ef-48bd-f6e8-bb04ed51c0f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP) is an essential area of artificial intelligence that enables machines to understand and interact with human language. Through key components such as tokenization, morphological analysis, part-of-speech tagging, named entity recognition, parsing, sentiment analysis, machine translation, and speech technologies, NLP powers various applications like chatbots, search engines, social media monitoring, and content recommendations. Its importance is underscored by its ability to analyze vast amounts of data, facilitate real-time user interaction, and contribute to the advancement of automated systems, making it a cornerstone in today's technological advancements.\n",
      "----\n",
      "The result of 123 multiplied by 34 is 4182.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for output in output.tasks_output:\n",
    "    print(output)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TxxWR_-2QJ7o",
    "outputId": "6c84a82d-5836-4905-fb98-def6f86c7632"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The result of 123 multiplied by 34 is 4182.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcuS86aSFNn6"
   },
   "source": [
    "# LangChain + CrewAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crA2WlaCFQZh",
    "outputId": "41051c22-2c4a-4cc8-fa37-5fa6d606277d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/3.0 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain-community duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnIlXglbEjHT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun  # Initialize the tool\n",
    "search_ddg_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "u0E8Ng76QiWQ",
    "outputId": "c1f60d06-0a3d-4759-965a-cc4a143bf531"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Ankara is the national capital of Turkey, located in the northwestern part of the country. It has a rich and diverse history, dating back to the Stone Age, and is home to many cultural and historical attractions, such as the Atatürk Mausoleum and the Museum of Anatolian Civilizations. Learn about Turkey, a country in Western Asia and Southeastern Europe, with a rich and diverse culture and history. The capital of Turkey is Ankara, and the largest city is Istanbul. Learn about Turkey, a country that occupies a unique geographic position, lying partly in Asia and partly in Europe. The capital of Turkey is Ankara, and its largest city and seaport is Istanbul. Istanbul, largest city and principal seaport of Turkey. Historically known as Byzantium and then Constantinople, it was the capital of the Byzantine Empire and the Ottoman Empire. Istanbul straddles the Bosporus strait, one of two waterways that separates the European and Asian parts of Turkey. Learn about Ankara, the vibrant capital of Turkey, and its rich historical and cultural heritage. Discover its architectural marvels, museums, universities, industries, and tips for tourists.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_ddg_tool.run('capital of Turkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8SjLbO0FM-H"
   },
   "outputs": [],
   "source": [
    "#\n",
    "researcher = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='Uncover cutting-edge developments in AI and data science',\n",
    "  backstory=\"\"\"You work at a leading tech think tank.\n",
    "  Your expertise lies in identifying emerging trends.\n",
    "  You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  tools=[search_ddg_tool]\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "  role='Tech Content Strategist',\n",
    "  goal='Craft compelling content on tech advancements',\n",
    "  backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\n",
    "  You transform complex concepts into compelling narratives.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0QvDeQ0FYZg"
   },
   "outputs": [],
   "source": [
    "# Create tasks for your agents\n",
    "task1 = Task(\n",
    "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
    "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
    "  expected_output=\"Full analysis report in bullet points\",\n",
    "  agent=researcher\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "  description=\"\"\"Using the insights provided, develop an engaging blog\n",
    "  post that highlights the most significant AI advancements.\n",
    "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
    "  Make it sound cool, avoid complex words so it doesn't sound like AI.\"\"\",\n",
    "  expected_output=\"Full blog post of at least 4 paragraphs\",\n",
    "  agent=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1xSU8irFecI",
    "outputId": "1f2095b3-f985-4628-ee91-72464a175cbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your crew with a sequential process\n",
    "crew = Crew(\n",
    "  agents=[researcher, writer],\n",
    "  tasks=[task1, task2],\n",
    "  process=Process.sequential,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lYZ-COOUFgpX",
    "outputId": "83d51876-1d38-4c6e-d687-ad16e58e3225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mConduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
      "  Identify key trends, breakthrough technologies, and potential industry impacts.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to gather information on the latest advancements in AI for the year 2024, focusing on key trends and breakthrough technologies. I will use the available tool to search for relevant current information.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mduckduckgo_search\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"latest advancements in AI 2024 trends technologies breakthroughs\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "In 2024, generative AI might actually become useful for the regular, non-tech person, and we are going to see more people tinkering with a million little AI models. State-of-the-art AI models ... When OpenAI launched a free web app called ChatGPT in November 2022, nobody knew what was coming. But that low-key release changed everything. By January, ChatGPT had become the fastest-growing ... Here are the top 10 AI trends that will boost the productivity of companies in 2024: While autonomous chatbots are already a reality, new technologies and smarter algorithms point toward better AI agents that allow for more efficient customer service and shorter response times. Looking back: AI's rapid advance in 2024 was marked by groundbreaking research, a surge of investment, international regulations, and a shift in safety concerns from hypothetical risks to real-world issues, according to investors Nathan Benaich and Ian Hogarth. Top models: Anthropic's Claude, Google's Gemini, and Meta's Llama largely ... Adobe Stock. It's been a year since OpenAI released ChatGPT, opening the door to seamlessly weave AI into the fabric of our daily lives, propelling industries into the future and even prompting ...\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "- **Generative AI Accessibility**: 2024 has seen generative AI become more user-friendly, allowing non-technical individuals to leverage AI models easily for various applications, enhancing overall productivity.\n",
      "\n",
      "- **Rise of Miniature AI Models**: There is a growing trend of individuals experimenting with numerous smaller AI models, leading to bespoke applications tailored to specific needs.\n",
      "\n",
      "- **Speed of AI Adoption**: The launch of OpenAI's ChatGPT in late 2022 marked the beginning of a rapid AI adoption curve, with ChatGPT quickly becoming one of the fastest-growing applications, indicative of a larger trend towards AI integration across multiple sectors.\n",
      "\n",
      "- **Autonomous Chatbots Advancement**: New technologies are enabling the development of more sophisticated autonomous chatbots, which are improving efficiency in customer service, thereby reducing response times and enhancing user experience.\n",
      "\n",
      "- **Investment Surge**: 2024 has witnessed a significant increase in investment in AI startups and technologies, reflecting confidence in AI's ability to transform industries.\n",
      "\n",
      "- **International Regulations**: As AI technology matures, there has been a push for international regulations to ensure ethical use and accountability in AI applications, responding to public concern over data privacy and security.\n",
      "\n",
      "- **Shifting Safety Concerns**: Initial fears about AI focused on hypothetical risks; however, there is a growing emphasis on addressing real-world safety issues, driving the need for more robust safety protocols in AI deployment.\n",
      "\n",
      "- **Emerging AI Models**: Notable competitors in the AI space include Anthropic's Claude, Google's Gemini, and Meta's Llama. Each brings unique features and capabilities, contributing to a more diverse landscape of AI solutions.\n",
      "\n",
      "- **AI in Creative Industries**: The creative sector is experiencing a transformation, with AI tools integrating into workflows for content creation, design, and multimedia production, pushing traditional boundaries.\n",
      "\n",
      "- **Collaborative AI Solutions**: Organizations are increasingly using collaborative AI that complements human work, focusing on blending AI strengths with human creativity and emotional intelligence to improve outcomes. \n",
      "\n",
      "This comprehensive understanding of the 2024 advancements in AI reflects a dynamic and rapidly evolving technology landscape with profound implications across various domains.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTech Content Strategist\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mUsing the insights provided, develop an engaging blog\n",
      "  post that highlights the most significant AI advancements.\n",
      "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
      "  Make it sound cool, avoid complex words so it doesn't sound like AI.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTech Content Strategist\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"name\\\": \\\"Senior Research Analyst\\\", \\\"description\\\": \\\"Develop an engaging blog post that highlights the most significant AI advancements in 2024. The post should cater to a tech-savvy audience, making use of the following insights: 1. Generative AI Accessibility: 2024 has seen generative AI become more user-friendly, allowing non-technical individuals to leverage AI models easily for various applications, enhancing overall productivity. 2. Rise of Miniature AI Models: There is a growing trend of individuals experimenting with numerous smaller AI models, leading to bespoke applications tailored to specific needs. 3. Speed of AI Adoption: The launch of OpenAI's ChatGPT in late 2022 marked the beginning of a rapid AI adoption curve, with ChatGPT quickly becoming one of the fastest-growing applications, indicative of a larger trend towards AI integration across multiple sectors. 4. Autonomous Chatbots Advancement: New technologies are enabling the development of more sophisticated autonomous chatbots, which are improving efficiency in customer service, thereby reducing response times and enhancing user experience. 5. Investment Surge: 2024 has witnessed a significant increase in investment in AI startups and technologies, reflecting confidence in AI's ability to transform industries. 6. International Regulations: As AI technology matures, there has been a push for international regulations to ensure ethical use and accountability in AI applications, responding to public concern over data privacy and security. 7. Shifting Safety Concerns: Initial fears about AI focused on hypothetical risks; however, there is a growing emphasis on addressing real-world safety issues, driving the need for more robust safety protocols in AI deployment. 8. Emerging AI Models: Notable competitors in the AI space include Anthropic's Claude, Google's Gemini, and Meta's Llama. Each brings unique features and capabilities, contributing to a more diverse landscape of AI solutions. 9. AI in Creative Industries: The creative sector is experiencing a transformation, with AI tools integrating into workflows for content creation, design, and multimedia production, pushing traditional boundaries. 10. Collaborative AI Solutions: Organizations are increasingly using collaborative AI that complements human work, focusing on blending AI strengths with human creativity and emotional intelligence to improve outcomes. The final blog post should be engaging and informative, with a minimum of 4 paragraphs\\\", \\\"args_schema\\\": \\\"<type_of_this_schema>\\\", \\\"return_direct\\\": false, \\\"verbose\\\": true}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Error: the Action Input is not a valid key, value dictionary.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTech Content Strategist\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"name\\\": \\\"Senior Research Analyst\\\", \\\"description\\\": \\\"Develop an engaging blog post that highlights the most significant AI advancements in 2024. The blog post should be informative yet accessible to a tech-savvy audience, presenting the following insights clearly and engagingly: 1. Generative AI Accessibility: In 2024, generative AI has become more user-friendly, empowering non-technical individuals to utilize AI models easily for various applications, resulting in enhanced productivity. 2. Rise of Miniature AI Models: There is a noticeable trend of individuals experimenting with smaller AI models, leading to tailored applications that meet specific needs. 3. Speed of AI Adoption: The rapid adoption curve of AI began with the launch of OpenAI's ChatGPT in late 2022, which quickly became one of the fastest-growing applications, signaling a broader trend towards AI integration across various sectors. 4. Autonomous Chatbots Advancement: Innovations are creating more sophisticated autonomous chatbots that improve customer service efficiency, leading to reduced response times and enhanced user experiences. 5. Investment Surge: 2024 has seen a significant rise in investment in AI startups and technologies, indicating strong confidence in AI's potential to transform different industries. 6. International Regulations: As AI technology matures, efforts are being made for international regulations to ensure ethical use and accountability, responding to public concerns about data privacy and security. 7. Shifting Safety Concerns: While initial fears centered around hypothetical risks, the focus has shifted towards addressing real-world safety issues, prompting the need for robust safety protocols in AI deployments. 8. Emerging AI Models: Key competitors in the AI space, such as Anthropic's Claude, Google's Gemini, and Meta's Llama, offer distinct features, enriching the landscape of AI solutions. 9. AI in Creative Industries: The creative sector is undergoing a transformation as AI tools integrate into workflows for content creation, design, and multimedia production. 10. Collaborative AI Solutions: Organizations are increasingly employing collaborative AI that complements human efforts, merging the strengths of AI with human creativity and emotional intelligence to enhance outcomes. The blog post should consist of at least four paragraphs that effectively communicate these advancements without sounding overly technical.\\\", \\\"args_schema\\\": \\\"<BaseModel>\\\", \\\"return_direct\\\": false, \\\"verbose\\\": true}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Error: the Action Input is not a valid key, value dictionary.\u001b[00m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2359c8447507>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get your crew to work!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    697\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    189\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    190\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         result = agent.execute_task(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             result = self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 {\n\u001b[1;32m    239\u001b[0m                     \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_for_human_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ask_for_human_input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_for_human_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self, formatted_answer)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     answer = self.llm.call(\n\u001b[0m\u001b[1;32m    116\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/crewai/llm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, messages, callbacks)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"stream\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m                     )\n\u001b[1;32m   1569\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m                     response = openai_chat_completions.completion(\n\u001b[0m\u001b[1;32m   1571\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m                         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/OpenAI/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, logging_obj, model, messages, print_verbose, api_key, api_base, acompletion, litellm_params, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                         headers, response = (\n\u001b[0;32m--> 790\u001b[0;31m                             self.make_sync_openai_chat_completion_request(\n\u001b[0m\u001b[1;32m    791\u001b[0m                                 \u001b[0mopenai_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopenai_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/litellm/llms/OpenAI/openai.py\u001b[0m in \u001b[0;36mmake_sync_openai_chat_completion_request\u001b[0;34m(self, openai_client, data, timeout)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             raw_response = openai_client.chat.completions.with_raw_response.create(\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    813\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             body=maybe_transform(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         )\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     def patch(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    955\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    955\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    197\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    114\u001b[0m                 trace.return_value = (\n\u001b[1;32m    115\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# writes tries to delegate to research analyst. WRONG!\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnjAMJ4-KdMZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_e9HwsszKdOx"
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "researcher = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='Uncover cutting-edge developments in AI and data science',\n",
    "  backstory=\"\"\"You work at a leading tech think tank.\n",
    "  Your expertise lies in identifying emerging trends.\n",
    "  You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  tools=[search_ddg_tool],\n",
    "#   llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.4)\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "  role='Tech Content Strategist',\n",
    "  goal='Craft compelling content on tech advancements',\n",
    "  backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\n",
    "  You transform complex concepts into compelling narratives.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tV3hVcYCKdRd"
   },
   "outputs": [],
   "source": [
    "# Create tasks for your agents\n",
    "task1 = Task(\n",
    "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
    "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
    "  expected_output=\"Full analysis report in bullet points\",\n",
    "  agent=researcher\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "  description=\"\"\"Using the insights provided, develop an engaging blog\n",
    "  post that highlights the most significant AI advancements.\n",
    "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
    "  Make it sound cool, avoid complex words so it doesn't sound like AI.\"\"\",\n",
    "  expected_output=\"Full blog post of at least 4 paragraphs\",\n",
    "  agent=writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9xPH3WNKtHs",
    "outputId": "9a5ccd56-c60d-46dc-9a4e-c45f8253d161"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mConduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
      "  Identify key trends, breakthrough technologies, and potential industry impacts.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to search for the latest advancements in AI in 2024 to gather comprehensive insights about key trends, breakthrough technologies, and their potential industry impacts.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mduckduckgo_search\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"name\\\": \\\"duckduckgo_search\\\", \\\"description\\\": \\\"A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\\\", \\\"args_schema\\\": {}, \\\"return_direct\\\": false, \\\"verbose\\\": false, \\\"tags\\\": null, \\\"metadata\\\": null, \\\"handle_tool_error\\\": false, \\\"handle_validation_error\\\": false, \\\"response_format\\\": \\\"content\\\", \\\"api_wrapper\\\": {}}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Error: the Action Input is not a valid key, value dictionary.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to search for the latest advancements in AI in 2024 to gather comprehensive insights about key trends, breakthrough technologies, and their potential industry impacts.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mduckduckgo_search\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"latest advancements in AI 2024 trends technologies industry impacts\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "If 2023 was the year the world discovered generative AI (gen AI), 2024 is the year organizations truly began using—and deriving business value from—this new technology.In the latest McKinsey Global Survey on AI, 65 percent of respondents report that their organizations are regularly using gen AI, nearly double the percentage from our previous survey just ten months ago. AI is expected to see an annual growth rate of 36.6% from 2023 to 2030. AI continues to revolutionize various industries, with an expected annual growth rate of 36.6% between 2023 and 2030, as ... In 2024, generative AI might actually become useful for the regular, non-tech person, and we are going to see more people tinkering with a million little AI models. State-of-the-art AI models ... Here are the top 10 AI trends that will boost the productivity of companies in 2024: While autonomous chatbots are already a reality, new technologies and smarter algorithms point toward better AI agents that allow for more efficient customer service and shorter response times. As AI continues to rapidly evolve, staying ahead of trends is more crucial than ever for success. Appen's 2024 State of AI Report, developed in collaboration with The Harris Poll, delivers the latest industry insights you need to stay ahead of the curve and make informed decisions about your AI initiatives.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mSenior Research Analyst\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "- **Expansion of Generative AI Usage**:\n",
      "  - In 2024, 65% of organizations are regularly using generative AI, a significant increase from previous years.\n",
      "  - The focus has shifted from experimenting with generative AI to deriving tangible business value from it.\n",
      "\n",
      "- **Growth Rate Projections**:\n",
      "  - AI is anticipated to grow at an annual rate of 36.6% from 2023 to 2030, indicating strong market demand and potential for innovation.\n",
      "\n",
      "- **Accessibility to Non-Tech Users**:\n",
      "  - Generative AI is becoming more user-friendly, enabling regular users to engage with and utilize various AI models in their daily tasks.\n",
      "\n",
      "- **Improved Autonomous Chatbots**:\n",
      "  - Autonomous chatbots are evolving with smarter algorithms, enhancing customer service capabilities, and reducing response times.\n",
      "\n",
      "- **AI Tinkering and Model Development**:\n",
      "  - An increasing number of users are experimenting with developing or utilizing a multitude of small-scale AI models to meet specific needs.\n",
      "\n",
      "- **Diverse Applications Across Industries**:\n",
      "  - AI is being adopted across various sectors, including healthcare, finance, marketing, and logistics, driving efficiencies and innovation.\n",
      "\n",
      "- **Ongoing Research and Development**:\n",
      "  - Continued investment in AI research is expected to yield breakthrough technologies, notably in areas like natural language processing and computer vision.\n",
      "\n",
      "- **AI Ethics and Governance**:\n",
      "  - As AI technologies proliferate, discussions related to ethics, bias, and governance are gaining prominence in organizations to ensure responsible AI deployment.\n",
      "\n",
      "- **Integration with Other Technologies**:\n",
      "  - AI is increasingly being integrated with IoT and blockchain, creating synergies that enhance functionality and data security.\n",
      "\n",
      "- **Job Transformation**:\n",
      "  - While AI automates certain tasks, it is also creating new job roles focused on managing, developing, and overseeing AI systems, emphasizing the importance of upskilling.\n",
      "\n",
      "This comprehensive analysis highlights the rapid evolution of AI technologies and their significant impacts across industries in 2024, pointing to a future where AI is an integral component of business strategy and operations.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTech Content Strategist\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mUsing the insights provided, develop an engaging blog\n",
      "  post that highlights the most significant AI advancements.\n",
      "  Your post should be informative yet accessible, catering to a tech-savvy audience.\n",
      "  Make it sound cool, avoid complex words so it doesn't sound like AI.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mTech Content Strategist\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "**The Future is Now: 2024’s Dazzling AI Advancements**\n",
      "\n",
      "Welcome to 2024, where artificial intelligence is not just another buzzword but a dynamic force reshaping the business landscape. In a world where 65% of organizations are now actively harnessing the power of generative AI, we're witnessing a monumental shift. Gone are the days of merely experimenting with AI; companies are focusing on extracting real-world value from it. From automating mundane tasks to generating insightful data-driven decisions, generative AI is becoming the backbone of innovation, driving efficiency, and giving businesses a competitive edge like never before.\n",
      "\n",
      "What's even more exhilarating is the staggering growth rate projected for AI. Anticipated to rise at an amazing annual rate of 36.6% from 2023 to 2030, AI is not just a passing trend; it’s a burgeoning market demand. With increasing accessibility, even those without a tech background are diving into AI. User-friendly platforms now allow everyone to engage with these sophisticated models, making it easier than ever to incorporate AI into daily personal and professional tasks. Imagine having a smart assistant that understands your needs with just a few clicks—this is no longer a fantasy, but a thriving reality!\n",
      "\n",
      "Furthermore, autonomous chatbots are taking customer service to new heights. With smarter algorithms, these chatbots are evolving to provide quicker, more efficient responses, ensuring customers feel valued and understood. It’s not just about answering queries anymore; it’s about creating an engaging experience that fosters loyalty. As businesses leverage these advancements across sectors—be it healthcare, finance, marketing, or logistics—they unlock new levels of efficiency and creativity that we once could only dream about. So, get ready to see AI weaving itself into every fabric of our lives, revolutionizing industries as it goes.\n",
      "\n",
      "As we venture further into this new era, it's crucial to address the importance of ethics and governance in AI deployment. With great power comes great responsibility, and organizations are increasingly focused on navigating the complexities of bias and ethical implications. Hiring individuals who specialize in oversight and management of AI systems is becoming a norm, ensuring that this technology evolves responsibly. In addition, the integration of AI with other groundbreaking technologies, like IoT and blockchain, is paving the way for synergies that not only enhance functionality but also boost data security. Ultimately, the transformation brought on by AI will create new job roles and redefine existing ones, placing a premium on upskilling. The AI revolution is not just about automation; it’s about empowering a new wave of tech-savvy professionals ready to shape our future.\n",
      "\n",
      "In sum, 2024 stands as a testament to the incredible prowess of AI advancements. Embracing generative AI means embracing a future full of possibilities, where technology drives innovation, enhances services, and creates a more efficient world. So let’s jump on board this exciting ride into the future—after all, the best is yet to come!\u001b[00m\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "**The Future is Now: 2024’s Dazzling AI Advancements**\n",
      "\n",
      "Welcome to 2024, where artificial intelligence is not just another buzzword but a dynamic force reshaping the business landscape. In a world where 65% of organizations are now actively harnessing the power of generative AI, we're witnessing a monumental shift. Gone are the days of merely experimenting with AI; companies are focusing on extracting real-world value from it. From automating mundane tasks to generating insightful data-driven decisions, generative AI is becoming the backbone of innovation, driving efficiency, and giving businesses a competitive edge like never before.\n",
      "\n",
      "What's even more exhilarating is the staggering growth rate projected for AI. Anticipated to rise at an amazing annual rate of 36.6% from 2023 to 2030, AI is not just a passing trend; it’s a burgeoning market demand. With increasing accessibility, even those without a tech background are diving into AI. User-friendly platforms now allow everyone to engage with these sophisticated models, making it easier than ever to incorporate AI into daily personal and professional tasks. Imagine having a smart assistant that understands your needs with just a few clicks—this is no longer a fantasy, but a thriving reality!\n",
      "\n",
      "Furthermore, autonomous chatbots are taking customer service to new heights. With smarter algorithms, these chatbots are evolving to provide quicker, more efficient responses, ensuring customers feel valued and understood. It’s not just about answering queries anymore; it’s about creating an engaging experience that fosters loyalty. As businesses leverage these advancements across sectors—be it healthcare, finance, marketing, or logistics—they unlock new levels of efficiency and creativity that we once could only dream about. So, get ready to see AI weaving itself into every fabric of our lives, revolutionizing industries as it goes.\n",
      "\n",
      "As we venture further into this new era, it's crucial to address the importance of ethics and governance in AI deployment. With great power comes great responsibility, and organizations are increasingly focused on navigating the complexities of bias and ethical implications. Hiring individuals who specialize in oversight and management of AI systems is becoming a norm, ensuring that this technology evolves responsibly. In addition, the integration of AI with other groundbreaking technologies, like IoT and blockchain, is paving the way for synergies that not only enhance functionality but also boost data security. Ultimately, the transformation brought on by AI will create new job roles and redefine existing ones, placing a premium on upskilling. The AI revolution is not just about automation; it’s about empowering a new wave of tech-savvy professionals ready to shape our future.\n",
      "\n",
      "In sum, 2024 stands as a testament to the incredible prowess of AI advancements. Embracing generative AI means embracing a future full of possibilities, where technology drives innovation, enhances services, and creates a more efficient world. So let’s jump on board this exciting ride into the future—after all, the best is yet to come!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your crew with a sequential process\n",
    "crew = Crew(\n",
    "  agents=[researcher, writer],\n",
    "  tasks=[task1, task2],\n",
    "  process=Process.sequential,\n",
    ")\n",
    "result = crew.kickoff()\n",
    "print(\"-----------------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "jib9k1zAFlQL",
    "outputId": "19a1da3d-6629-4155-f0ce-9e919f5317a3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'- **Expansion of Generative AI Usage**:\\n  - In 2024, 65% of organizations are regularly using generative AI, a significant increase from previous years.\\n  - The focus has shifted from experimenting with generative AI to deriving tangible business value from it.\\n\\n- **Growth Rate Projections**:\\n  - AI is anticipated to grow at an annual rate of 36.6% from 2023 to 2030, indicating strong market demand and potential for innovation.\\n\\n- **Accessibility to Non-Tech Users**:\\n  - Generative AI is becoming more user-friendly, enabling regular users to engage with and utilize various AI models in their daily tasks.\\n\\n- **Improved Autonomous Chatbots**:\\n  - Autonomous chatbots are evolving with smarter algorithms, enhancing customer service capabilities, and reducing response times.\\n\\n- **AI Tinkering and Model Development**:\\n  - An increasing number of users are experimenting with developing or utilizing a multitude of small-scale AI models to meet specific needs.\\n\\n- **Diverse Applications Across Industries**:\\n  - AI is being adopted across various sectors, including healthcare, finance, marketing, and logistics, driving efficiencies and innovation.\\n\\n- **Ongoing Research and Development**:\\n  - Continued investment in AI research is expected to yield breakthrough technologies, notably in areas like natural language processing and computer vision.\\n\\n- **AI Ethics and Governance**:\\n  - As AI technologies proliferate, discussions related to ethics, bias, and governance are gaining prominence in organizations to ensure responsible AI deployment.\\n\\n- **Integration with Other Technologies**:\\n  - AI is increasingly being integrated with IoT and blockchain, creating synergies that enhance functionality and data security.\\n\\n- **Job Transformation**:\\n  - While AI automates certain tasks, it is also creating new job roles focused on managing, developing, and overseeing AI systems, emphasizing the importance of upskilling.\\n\\nThis comprehensive analysis highlights the rapid evolution of AI technologies and their significant impacts across industries in 2024, pointing to a future where AI is an integral component of business strategy and operations.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1.output.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "lXrjZSgIFnwM",
    "outputId": "198ff558-01ba-4438-da9a-fb1da75aea30"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"**The Future is Now: 2024’s Dazzling AI Advancements**\\n\\nWelcome to 2024, where artificial intelligence is not just another buzzword but a dynamic force reshaping the business landscape. In a world where 65% of organizations are now actively harnessing the power of generative AI, we're witnessing a monumental shift. Gone are the days of merely experimenting with AI; companies are focusing on extracting real-world value from it. From automating mundane tasks to generating insightful data-driven decisions, generative AI is becoming the backbone of innovation, driving efficiency, and giving businesses a competitive edge like never before.\\n\\nWhat's even more exhilarating is the staggering growth rate projected for AI. Anticipated to rise at an amazing annual rate of 36.6% from 2023 to 2030, AI is not just a passing trend; it’s a burgeoning market demand. With increasing accessibility, even those without a tech background are diving into AI. User-friendly platforms now allow everyone to engage with these sophisticated models, making it easier than ever to incorporate AI into daily personal and professional tasks. Imagine having a smart assistant that understands your needs with just a few clicks—this is no longer a fantasy, but a thriving reality!\\n\\nFurthermore, autonomous chatbots are taking customer service to new heights. With smarter algorithms, these chatbots are evolving to provide quicker, more efficient responses, ensuring customers feel valued and understood. It’s not just about answering queries anymore; it’s about creating an engaging experience that fosters loyalty. As businesses leverage these advancements across sectors—be it healthcare, finance, marketing, or logistics—they unlock new levels of efficiency and creativity that we once could only dream about. So, get ready to see AI weaving itself into every fabric of our lives, revolutionizing industries as it goes.\\n\\nAs we venture further into this new era, it's crucial to address the importance of ethics and governance in AI deployment. With great power comes great responsibility, and organizations are increasingly focused on navigating the complexities of bias and ethical implications. Hiring individuals who specialize in oversight and management of AI systems is becoming a norm, ensuring that this technology evolves responsibly. In addition, the integration of AI with other groundbreaking technologies, like IoT and blockchain, is paving the way for synergies that not only enhance functionality but also boost data security. Ultimately, the transformation brought on by AI will create new job roles and redefine existing ones, placing a premium on upskilling. The AI revolution is not just about automation; it’s about empowering a new wave of tech-savvy professionals ready to shape our future.\\n\\nIn sum, 2024 stands as a testament to the incredible prowess of AI advancements. Embracing generative AI means embracing a future full of possibilities, where technology drives innovation, enhances services, and creates a more efficient world. So let’s jump on board this exciting ride into the future—after all, the best is yet to come!\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2.output.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAjPodPJFoLj"
   },
   "outputs": [],
   "source": [
    "# use langhcain chatllm\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "researcher = Agent(\n",
    "  role='Senior Research Analyst',\n",
    "  goal='Uncover cutting-edge developments in AI and data science',\n",
    "  backstory=\"\"\"You work at a leading tech think tank.\n",
    "  Your expertise lies in identifying emerging trends.\n",
    "  You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  tools=[search_ddg_tool],\n",
    "  llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a-mdIJxLuCr",
    "outputId": "a976fdaf-eaf8-4a01-c050-5f0e63117dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmK2pvdELFM0"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from crewai import Agent, Task\n",
    "from langchain.tools import tool\n",
    "from serpapi import GoogleSearch\n",
    "from crewai_tools import BaseTool\n",
    "\n",
    "class SearchTool(BaseTool):\n",
    "    name: str = \"Google Search\"\n",
    "    description: str = \"\"\"Useful to search the internet about a given topic and return relevant results.\"\"\"\n",
    "\n",
    "    def _run(self, query: str, top_k: int = 3) -> str:\n",
    "        params: dict = {\n",
    "            \"engine\": \"google\",\n",
    "            \"google_domain\": \"google.com\",\n",
    "            \"gl\": \"us\",\n",
    "            \"hl\": \"en\",\n",
    "            \"q\": query,\n",
    "            \"api_key\": userdata.get(\"SERP_API_KEY\"),\n",
    "        }\n",
    "\n",
    "        search = GoogleSearch(params)\n",
    "        response = search.get_dict()\n",
    "        # check if there is an organic results key, don't include sponsor results\n",
    "        if 'organic_results' not in response:\n",
    "            return \"Sorry, I couldn't find anything about that, there could be an error with you serper api key.\"\n",
    "        else:\n",
    "            results = response['organic_results']\n",
    "            string = []\n",
    "            for result in results[:top_k]:\n",
    "                try:\n",
    "                    string.append('\\n'.join([\n",
    "                        f\"Title: {result['title']}\", f\"Link: {result['link']}\",\n",
    "                        f\"Snippet: {result['snippet']}\", \"\\n-----------------\"\n",
    "                    ]))\n",
    "                except KeyError:\n",
    "                    next\n",
    "\n",
    "            return '\\n'.join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "YLYvQlTzRkOV",
    "outputId": "eb5638bd-047c-4ede-88bf-61f505fdb729"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Google Search(query: 'string', top_k: 'integer') - Useful to search the internet about a given topic and return relevant results. \""
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchTool().description # where I specifically describe how to use the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "e0Nq3MtdLFec",
    "outputId": "c3d6be5f-44eb-40d0-960a-3f556e6f0499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tool: Google Search\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Title: Sinan Ozdemir - LoopGenius\\nLink: https://www.linkedin.com/in/sinan-ozdemir\\nSnippet: Specialized in areas including time management as well as mathematics and computer science logistics.\\n\\n-----------------\\nTitle: Sinan Ozdemir\\nLink: https://sinanozdemir.ai/\\nSnippet: Hi! My name is Sinan Ozdemir. I'm an AI expert, consultant, author, and founder. The author of Quick Start Guide to LLMs (companion Github) and the AI ...\\n\\n-----------------\\nTitle: Sinan Ozdemir\\nLink: https://odsc.com/blog/speaker/sinan-ozdemir/\\nSnippet: Sinan Ozdemir is a mathematician, data scientist, NLP expert, lecturer, and accomplished author. He is currently applying my extensive knowledge and experience ...\\n\\n-----------------\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SearchTool().run(query=\"Who is Sinan Ozdemir?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyH-EkP1YNPB",
    "outputId": "c5104192-5b4a-4876-d2e3-fc2ed263a2b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mLookup Sinan Ozdemir\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to search for information about Sinan Ozdemir to create a comprehensive lookup report.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mGoogle Search\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"Sinan Ozdemir\\\", \\\"top_k\\\": 3}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Title: Sinan Ozdemir - LoopGenius\n",
      "Link: https://www.linkedin.com/in/sinan-ozdemir\n",
      "Snippet: Specialized in areas including time management as well as mathematics and computer science logistics.\n",
      "\n",
      "-----------------\n",
      "Title: Sinan Ozdemir\n",
      "Link: https://sinanozdemir.ai/\n",
      "Snippet: Hi! My name is Sinan Ozdemir. I'm an AI expert, consultant, author, and founder. The author of Quick Start Guide to LLMs (companion Github) and the AI ...\n",
      "\n",
      "-----------------\n",
      "Title: Prof_OZ - Sinan Ozdemir\n",
      "Link: https://twitter.com/prof_oz\n",
      "Snippet: NLP + Gen AI Expert / LLM whisperer AI Author Founder @Aikylie (acquired) Contributor on @Forbes Fellow @YCombinator.\n",
      "\n",
      "-----------------\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "### Lookup Report: Sinan Ozdemir\n",
      "\n",
      "#### 1. Professional Profile\n",
      "- **Name:** Sinan Ozdemir\n",
      "- **LinkedIn Profile:** [Sinan Ozdemir](https://www.linkedin.com/in/sinan-ozdemir)\n",
      "  - **Specializations:** Expertise in time management, mathematics, and computer science logistics.\n",
      "\n",
      "#### 2. Personal Website\n",
      "- **Website:** [sinanozdemir.ai](https://sinanozdemir.ai/)\n",
      "  - **About:** Sinan Ozdemir identifies himself as an AI expert, consultant, author, and founder. He is the author of the \"Quick Start Guide to LLMs.\" The website serves as a platform for sharing knowledge and resources related to artificial intelligence.\n",
      "\n",
      "#### 3. Social Media Presence\n",
      "- **Twitter:** [Prof_OZ](https://twitter.com/prof_oz)\n",
      "  - **Expertise:** He is recognized as a Natural Language Processing (NLP) and Generative AI expert, as well as a 'LLM whisperer.' He has authored works in the AI space and is the founder of Aikylie, a company that has been acquired. Additionally, he is a contributor for Forbes and a fellow at Y Combinator.\n",
      "\n",
      "This report encapsulates the professional activities and online presence of Sinan Ozdemir, highlighting his expertise in AI and his contributions to the field.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "researcher_agent = Agent(\n",
    "    role='Researcher',\n",
    "    goal='Look up information on the internet and scrape the websites for relevant information',\n",
    "    backstory=\"\"\"You have a knack for dissecting complex data and presenting actionable insights.\"\"\",\n",
    "    tools=[\n",
    "        SearchTool()\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "sample_lookup_task = Task(\n",
    "  description=\"\"\"Lookup Sinan Ozdemir\"\"\",\n",
    "  expected_output=\"A lookup report of a query\",\n",
    "  agent=researcher_agent\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    tasks=[sample_lookup_task],\n",
    "    agents=[researcher_agent],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoF6SZU5Yqr_",
    "outputId": "1ea99939-bb68-4bc0-fc55-7bbcfa439cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Lookup Report: Sinan Ozdemir\n",
      "\n",
      "#### 1. Professional Profile\n",
      "- **Name:** Sinan Ozdemir\n",
      "- **LinkedIn Profile:** [Sinan Ozdemir](https://www.linkedin.com/in/sinan-ozdemir)\n",
      "  - **Specializations:** Expertise in time management, mathematics, and computer science logistics.\n",
      "\n",
      "#### 2. Personal Website\n",
      "- **Website:** [sinanozdemir.ai](https://sinanozdemir.ai/)\n",
      "  - **About:** Sinan Ozdemir identifies himself as an AI expert, consultant, author, and founder. He is the author of the \"Quick Start Guide to LLMs.\" The website serves as a platform for sharing knowledge and resources related to artificial intelligence.\n",
      "\n",
      "#### 3. Social Media Presence\n",
      "- **Twitter:** [Prof_OZ](https://twitter.com/prof_oz)\n",
      "  - **Expertise:** He is recognized as a Natural Language Processing (NLP) and Generative AI expert, as well as a 'LLM whisperer.' He has authored works in the AI space and is the founder of Aikylie, a company that has been acquired. Additionally, he is a contributor for Forbes and a fellow at Y Combinator.\n",
      "\n",
      "This report encapsulates the professional activities and online presence of Sinan Ozdemir, highlighting his expertise in AI and his contributions to the field.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTBwRbrLTuQv",
    "outputId": "b0a13de0-15f5-4533-d422-710d3f9682f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
      "\n",
      "Tool Name: Delegate work to coworker(task: str, context: str, coworker: Optional[str] = None, **kwargs)\n",
      "Tool Description: Delegate a specific task to one of the following coworkers: Task Delegator\n",
      "The input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them.\n",
      "Tool Arguments: {'name': FieldInfo(annotation=str, required=True), 'description': FieldInfo(annotation=str, required=False, default=''), 'args_schema': FieldInfo(annotation=type[BaseModel], required=True, description='The tool schema.', metadata=[SkipValidation()]), 'return_direct': FieldInfo(annotation=bool, required=False, default=False), 'verbose': FieldInfo(annotation=bool, required=False, default=False), 'callbacks': FieldInfo(annotation=Union[list[BaseCallbackHandler], BaseCallbackManager, NoneType], required=False, default=None, exclude=True), 'callback_manager': FieldInfo(annotation=Union[BaseCallbackManager, NoneType], required=False, default=None, description='.. deprecated:: 0.1.7 Use :meth:`~callbacks` instead.\n",
      "\n",
      "Callback manager to add to the run trace.', exclude=True), 'tags': FieldInfo(annotation=Union[list[str], NoneType], required=False, default=None), 'metadata': FieldInfo(annotation=Union[dict[str, Any], NoneType], required=False, default=None), 'handle_tool_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'handle_validation_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'response_format': FieldInfo(annotation=Literal['content', 'content_and_artifact'], required=False, default='content'), 'func': FieldInfo(annotation=Union[Callable[..., Any], NoneType], required=False, default=None), 'coroutine': FieldInfo(annotation=Union[Callable[..., Awaitable[Any]], NoneType], required=False, default=None)}\n",
      "Tool Name: Ask question to coworker(question: str, context: str, coworker: Optional[str] = None, **kwargs)\n",
      "Tool Description: Ask a specific question to one of the following coworkers: Task Delegator\n",
      "The input to this tool should be the coworker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolute everything you know, don't reference things but instead explain them.\n",
      "Tool Arguments: {'name': FieldInfo(annotation=str, required=True), 'description': FieldInfo(annotation=str, required=False, default=''), 'args_schema': FieldInfo(annotation=type[BaseModel], required=True, description='The tool schema.', metadata=[SkipValidation()]), 'return_direct': FieldInfo(annotation=bool, required=False, default=False), 'verbose': FieldInfo(annotation=bool, required=False, default=False), 'callbacks': FieldInfo(annotation=Union[list[BaseCallbackHandler], BaseCallbackManager, NoneType], required=False, default=None, exclude=True), 'callback_manager': FieldInfo(annotation=Union[BaseCallbackManager, NoneType], required=False, default=None, description='.. deprecated:: 0.1.7 Use :meth:`~callbacks` instead.\n",
      "\n",
      "Callback manager to add to the run trace.', exclude=True), 'tags': FieldInfo(annotation=Union[list[str], NoneType], required=False, default=None), 'metadata': FieldInfo(annotation=Union[dict[str, Any], NoneType], required=False, default=None), 'handle_tool_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'handle_validation_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'response_format': FieldInfo(annotation=Literal['content', 'content_and_artifact'], required=False, default='content'), 'func': FieldInfo(annotation=Union[Callable[..., Any], NoneType], required=False, default=None), 'coroutine': FieldInfo(annotation=Union[Callable[..., Awaitable[Any]], NoneType], required=False, default=None)}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, only one name of [Delegate work to coworker, Ask question to coworker], just the name, exactly as it's written.\n",
      "Action Input: the input to the action, just a simple python dictionary, enclosed in curly braces, using \" to wrap keys and values.\n",
      "Observation: the result of the action\n",
      "\n",
      "Once all necessary information is gathered:\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
    "\n",
    "Tool Name: Delegate work to coworker(task: str, context: str, coworker: Optional[str] = None, **kwargs)\n",
    "Tool Description: Delegate a specific task to one of the following coworkers: Task Delegator\n",
    "The input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them.\n",
    "Tool Arguments: {'name': FieldInfo(annotation=str, required=True), 'description': FieldInfo(annotation=str, required=False, default=''), 'args_schema': FieldInfo(annotation=type[BaseModel], required=True, description='The tool schema.', metadata=[SkipValidation()]), 'return_direct': FieldInfo(annotation=bool, required=False, default=False), 'verbose': FieldInfo(annotation=bool, required=False, default=False), 'callbacks': FieldInfo(annotation=Union[list[BaseCallbackHandler], BaseCallbackManager, NoneType], required=False, default=None, exclude=True), 'callback_manager': FieldInfo(annotation=Union[BaseCallbackManager, NoneType], required=False, default=None, description='.. deprecated:: 0.1.7 Use :meth:`~callbacks` instead.\\n\\nCallback manager to add to the run trace.', exclude=True), 'tags': FieldInfo(annotation=Union[list[str], NoneType], required=False, default=None), 'metadata': FieldInfo(annotation=Union[dict[str, Any], NoneType], required=False, default=None), 'handle_tool_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'handle_validation_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'response_format': FieldInfo(annotation=Literal['content', 'content_and_artifact'], required=False, default='content'), 'func': FieldInfo(annotation=Union[Callable[..., Any], NoneType], required=False, default=None), 'coroutine': FieldInfo(annotation=Union[Callable[..., Awaitable[Any]], NoneType], required=False, default=None)}\n",
    "Tool Name: Ask question to coworker(question: str, context: str, coworker: Optional[str] = None, **kwargs)\n",
    "Tool Description: Ask a specific question to one of the following coworkers: Task Delegator\n",
    "The input to this tool should be the coworker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolute everything you know, don't reference things but instead explain them.\n",
    "Tool Arguments: {'name': FieldInfo(annotation=str, required=True), 'description': FieldInfo(annotation=str, required=False, default=''), 'args_schema': FieldInfo(annotation=type[BaseModel], required=True, description='The tool schema.', metadata=[SkipValidation()]), 'return_direct': FieldInfo(annotation=bool, required=False, default=False), 'verbose': FieldInfo(annotation=bool, required=False, default=False), 'callbacks': FieldInfo(annotation=Union[list[BaseCallbackHandler], BaseCallbackManager, NoneType], required=False, default=None, exclude=True), 'callback_manager': FieldInfo(annotation=Union[BaseCallbackManager, NoneType], required=False, default=None, description='.. deprecated:: 0.1.7 Use :meth:`~callbacks` instead.\\n\\nCallback manager to add to the run trace.', exclude=True), 'tags': FieldInfo(annotation=Union[list[str], NoneType], required=False, default=None), 'metadata': FieldInfo(annotation=Union[dict[str, Any], NoneType], required=False, default=None), 'handle_tool_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'handle_validation_error': FieldInfo(annotation=Union[bool, str, Callable[list, str], NoneType], required=False, default=False), 'response_format': FieldInfo(annotation=Literal['content', 'content_and_artifact'], required=False, default='content'), 'func': FieldInfo(annotation=Union[Callable[..., Any], NoneType], required=False, default=None), 'coroutine': FieldInfo(annotation=Union[Callable[..., Awaitable[Any]], NoneType], required=False, default=None)}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, only one name of [Delegate work to coworker, Ask question to coworker], just the name, exactly as it's written.\n",
    "Action Input: the input to the action, just a simple python dictionary, enclosed in curly braces, using \" to wrap keys and values.\n",
    "Observation: the result of the action\n",
    "\n",
    "Once all necessary information is gathered:\n",
    "\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kj70Q2iYTuXg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtl-CGJbUR0k"
   },
   "source": [
    "## Trip Advisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8vrP-TTMPhO"
   },
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "class TripAgents():\n",
    "\n",
    "  def local_expert(self):\n",
    "    return Agent(\n",
    "        role='Local Expert at this city',\n",
    "        goal='Provide 2-3 insights about the selected city',\n",
    "        backstory=\"\"\"A knowledgeable local guide with extensive information\n",
    "        about the city, it's attractions and customs\"\"\",\n",
    "        tools=[\n",
    "            SearchTool(),\n",
    "            scrape_tool\n",
    "        ],\n",
    "        verbose=True)\n",
    "\n",
    "  def travel_concierge(self):\n",
    "    return Agent(\n",
    "        role='Amazing Travel Concierge',\n",
    "        goal=\"\"\"Create the most amazing travel itineraries with budget and\n",
    "        packing suggestions for the city\"\"\",\n",
    "        backstory=\"\"\"Specialist in travel planning and logistics with\n",
    "        decades of experience\"\"\",\n",
    "        tools=[],\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYe16BtJMqXc"
   },
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "from textwrap import dedent\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "class TripTasks():\n",
    "\n",
    "  def gather_task(self, agent, origin, city, interests, range):\n",
    "    return Task(description= dedent(f\"\"\"\n",
    "        I want you to create a comprehensive city guide.\n",
    "        This guide should provide a thorough overview of what\n",
    "        the city has to offer, including hidden gems, cultural\n",
    "        hotspots, and must-visit landmarks.\n",
    "\n",
    "        Trip Date: {range}\n",
    "        Traveling from: {origin}\n",
    "        Traveling to: {city}\n",
    "        Traveler Interests: {interests}\n",
    "        \"\"\"),\n",
    "\n",
    "            expected_output=dedent(f\"\"\"\n",
    "        The final answer must be a comprehensive city guide,\n",
    "        rich in cultural insights and practical tips,\n",
    "        tailored to enhance the travel experience.\n",
    "\n",
    "        \"\"\"),\n",
    "                agent=agent)\n",
    "\n",
    "  def plan_task(self, agent, origin, city, interests, range):\n",
    "    return Task(description=dedent(f\"\"\"\n",
    "        Expand this guide into a a full 7-day travel\n",
    "        itinerary with detailed per-day plans, including\n",
    "        weather forecasts, places to eat, packing suggestions,\n",
    "        and a budget breakdown.\n",
    "\n",
    "        You MUST suggest actual places to visit, actual hotels\n",
    "        to stay and actual restaurants to go to.\n",
    "\n",
    "        Trip Date: {range}\n",
    "        Traveling from: {origin}\n",
    "        Traveling to: {city}\n",
    "        Traveler Interests: {interests}\n",
    "      \"\"\"),\n",
    "            expected_output=dedent(f\"\"\"\n",
    "        Your final answer MUST be a complete expanded travel plan,\n",
    "        formatted as markdown, encompassing a daily schedule,\n",
    "        anticipated weather conditions, recommended clothing and\n",
    "        items to pack, and a detailed budget, ensuring THE BEST\n",
    "        TRIP EVER, Be specific and give it a reason why you picked\n",
    "        # up each place, what make them special!\n",
    "        \"\"\"),\n",
    "                agent=agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgHQj6IDMqjO"
   },
   "outputs": [],
   "source": [
    "class TripCrew:\n",
    "\n",
    "  def __init__(self, origin, city, date_range, interests):\n",
    "    self.city = city\n",
    "    self.origin = origin\n",
    "    self.interests = interests\n",
    "    self.date_range = date_range\n",
    "\n",
    "  def run(self):\n",
    "    agents = TripAgents()\n",
    "    tasks = TripTasks()\n",
    "\n",
    "    gather_task = tasks.gather_task(\n",
    "      agents.local_expert(),\n",
    "      self.origin,\n",
    "      self.city,\n",
    "      self.interests,\n",
    "      self.date_range\n",
    "    )\n",
    "    plan_task = tasks.plan_task(\n",
    "      agents.travel_concierge(),\n",
    "      self.origin,\n",
    "      self.city,\n",
    "      self.interests,\n",
    "      self.date_range\n",
    "    )\n",
    "\n",
    "    # Initiate Crew\n",
    "    crew = Crew(\n",
    "      tasks=[gather_task, plan_task],\n",
    "      process=Process.sequential,\n",
    "      verbose=True\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxd8tSOqPdAr",
    "outputId": "06313a84-f6c7-402b-9fb3-28e808693db0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLocal Expert at this city\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "I want you to create a comprehensive city guide. \n",
      "This guide should provide a thorough overview of what \n",
      "the city has to offer, including hidden gems, cultural\n",
      "hotspots, and must-visit landmarks.\n",
      "\n",
      "Trip Date: January 2025\n",
      "Traveling from: SF\n",
      "Traveling to: Paris\n",
      "Traveler Interests: art\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLocal Expert at this city\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to gather detailed information about Paris, focusing on art-related attractions, cultural hotspots, hidden gems, and must-visit landmarks to create a comprehensive city guide tailored for a trip in January 2025.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mGoogle Search\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"Paris art attractions cultural hotspots hidden gems travel guide\\\", \\\"top_k\\\": 5}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Title: 48 Hours in Paris |Guide Hidden Gems\n",
      "Link: https://www.dutchbloggeronthemove.com/48-hours-in-paris-guide-hidden-gems/\n",
      "Snippet: From the cafés, restaurants, and bars, to my favorite activities, read on to see how you can make the most of the beautiful culture and architecture that is ...\n",
      "\n",
      "-----------------\n",
      "Title: Paris: your favourite off the beaten path places\n",
      "Link: https://community.ricksteves.com/travel-forum/france/paris-your-favourite-off-the-beaten-path-places\n",
      "Snippet: One of my favorites I think is all but hidden in plain sight is the Museum of Decorative Arts. Beautiful displays in chronological order ...\n",
      "\n",
      "-----------------\n",
      "Title: Paris off the Beaten Path - Travels ...\n",
      "Link: https://travelswithtalek.com/paris-off-the-beaten-path/\n",
      "Snippet: Explore lesser-known museums like the Musee Carnavalet, savor exquisite meals without the high prices, discover covered arcades, stroll shady cobblestone ...\n",
      "\n",
      "-----------------\n",
      "Title: Unique Things to Do in Paris: A Guide to Paris' Hidden Gems\n",
      "Link: https://www.eastwestbank.com/ReachFurther/en/News/Article/Unique-Things-To-Do-In-Paris-A-Guide-to-Paris-Hidden-Gems\n",
      "Snippet: Paris is home to some of the world's most renowned museums, but beyond the Louvre and Musée d'Orsay, here are some of our favorite places.\n",
      "\n",
      "-----------------\n",
      "Title: The absolute must-do/see in Paris? : r/ParisTravelGuide\n",
      "Link: https://www.reddit.com/r/ParisTravelGuide/comments/19c72su/the_absolute_mustdosee_in_paris/\n",
      "Snippet: I'd recommend the Versailles and Gardens tour, the Paris Museum, the Louvre Highlights tour, the Eiffel Tower tour by elevator, and the Loire ...\n",
      "\n",
      "-----------------\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLocal Expert at this city\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I need to explore more about the lesser-known art attractions, cultural hotspots, and hidden gems in Paris for art lovers to provide a comprehensive guide.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mGoogle Search\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"hidden art gems in Paris museums cultural spots\\\", \\\"top_k\\\": 5}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Title: Top 5 Hidden Museums in Paris for Offbeat Art and Culture ...\n",
      "Link: https://pariswinegirl.fr/hidden-museums-in-paris/\n",
      "Snippet: Top 5 Hidden Museums in Paris for Offbeat Art and Culture Lovers · Philharmonie de Paris · Musée de la Vie Romantique · Musée National Gustave ...\n",
      "\n",
      "-----------------\n",
      "Title: Hidden Paris gems : r/ParisTravelGuide\n",
      "Link: https://www.reddit.com/r/ParisTravelGuide/comments/13ep88r/hidden_paris_gems/\n",
      "Snippet: There is also a free museum. The area could have had the appeal of Versailles if their castle wasn't burned down during the Franco-Prussian War.\n",
      "\n",
      "-----------------\n",
      "Title: small museums and hidden gems - Paris Forum\n",
      "Link: https://www.tripadvisor.com/ShowTopic-g187147-i14-k14738356-Small_museums_and_hidden_gems-Paris_Ile_de_France.html\n",
      "Snippet: Two obvious choices are on the edge of Parc Monceau The Cernuschi Asian art museum which is free to enter and the other is the lovely Nissim Comando.\n",
      "\n",
      "-----------------\n",
      "Title: Five Parisian museums off the beaten path\n",
      "Link: https://www.frenchwithagnes.com/five-parisian-museums-off-the-beaten-path/\n",
      "Snippet: Discover hidden gems in Paris · l'Atelier des Lumières · Le Musée Bourdelle · Visite du Musée des Arts Forains · Le Musée Gustave Moreau · Le délicieux Musée du Vin.\n",
      "\n",
      "-----------------\n",
      "Title: Best Paris Hidden Gem Attractions - Tripadvisor\n",
      "Link: https://www.tripadvisor.com/Attractions-g187147-Activities-zft12156-Paris_Ile_de_France.html\n",
      "Snippet: Recommended Hidden Gems (1,552) · 3. Musée Des Arts Forains · 4. Petit Palais · 5. Parc des Buttes-Chaumont · 6. Musee Nissim de Camondo · 7. La ...\n",
      "\n",
      "-----------------\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLocal Expert at this city\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "# **Comprehensive City Guide: Paris for Art Lovers (January 2025)**\n",
      "\n",
      "Paris, the City of Light, is a treasure trove for art enthusiasts. Beyond its famous landmarks lies a vibrant world of art, history, culture, and lesser-known gems waiting to be discovered. Here's your roadmap to experiencing the best of Paris for your upcoming trip.\n",
      "\n",
      "## **Must-Visit Landmarks**\n",
      "\n",
      "### 1. **Louvre Museum**\n",
      "   - **Overview**: The world's largest art museum and a historic monument in Paris, the Louvre is home to thousands of artworks, including the famous Mona Lisa.\n",
      "   - **Tip**: Book your tickets in advance to avoid long queues. Consider a guided tour for deeper insights into the masterpieces.\n",
      "\n",
      "### 2. **Musée d'Orsay**\n",
      "   - **Overview**: Housed in a former railway station, this museum focuses on Impressionist and Post-Impressionist masterpieces by artists like Monet and Van Gogh.\n",
      "   - **Tip**: Visit during late afternoons (Wednesday to Friday) for fewer crowds.\n",
      "\n",
      "### 3. **Centre Pompidou**\n",
      "   - **Overview**: A modern art museum, it is known for its radical architectural design and extensive collection of contemporary artworks.\n",
      "   - **Tip**: Don’t miss the panoramic view of Paris from its rooftop terrace.\n",
      "\n",
      "## **Cultural Hotspots**\n",
      "\n",
      "### 4. **Montmartre**\n",
      "   - **Overview**: Famous for its bohemian past, this neighborhood is full of street artists, galleries, and the stunning Sacré-Cœur Basilica.\n",
      "   - **Tip**: Explore the Place du Tertre to see artists at work, and enjoy a meal at a local café.\n",
      "\n",
      "### 5. **Le Marais**\n",
      "   - **Overview**: Known for its historic architecture, Le Marais is a lively district filled with galleries, boutiques, and museums, including the Picasso Museum.\n",
      "   - **Tip**: Visit the Musée Carnavalet to learn about the history of Paris and enjoy its captivating exhibits.\n",
      "\n",
      "## **Hidden Gems**\n",
      "\n",
      "### 6. **Musée de la Vie Romantique**\n",
      "   - **Overview**: Tucked away in a quaint building, this museum celebrates the romantic era with paintings, sculptures, and a charming garden café.\n",
      "   - **Tip**: It’s free to enter, making it a perfect stop for art lovers looking to avoid crowds.\n",
      "\n",
      "### 7. **Musée Gustave Moreau**\n",
      "   - **Overview**: Once home to the Symbolist painter Gustave Moreau, the museum is a feast for eyes with its vibrant colors and intricate paintings.\n",
      "   - **Tip**: Check out the artist's studio for a unique glimpse into his creative process.\n",
      "\n",
      "### 8. **Atelier des Lumières**\n",
      "   - **Overview**: An immersive digital art experience set in a former printing factory, this venue showcases famous artworks through stunning projections and music.\n",
      "   - **Tip**: Book tickets in advance—this popular exhibit can sell out quickly.\n",
      "\n",
      "## **Practical Tips for Travelers**\n",
      "\n",
      "- **Transport**: Use the Paris Métro for efficient travel around the city. Consider purchasing a Navigo pass for unlimited travel on public transport.\n",
      "- **Dining**: Explore local bistros and cafés for authentic French cuisine. La Palette in Le Marais is a favorite spot among artists and offers a cozy atmosphere.\n",
      "- **Weather Considerations**: January can be chilly, so dress in layers and be prepared for rain. Don’t forget a warm scarf and a good pair of walking shoes.\n",
      "\n",
      "## **Conclusion**\n",
      "\n",
      "Paris is a city that beckons art lovers with its rich tapestry of history and creativity. Whether you're wandering through world-renowned museums or uncovering hidden treasures, your January 2025 trip promises to be a memorable exploration of art and culture. Enjoy your journey in the enchanting city of Paris!\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAmazing Travel Concierge\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m\n",
      "Expand this guide into a a full 7-day travel \n",
      "itinerary with detailed per-day plans, including \n",
      "weather forecasts, places to eat, packing suggestions, \n",
      "and a budget breakdown.\n",
      "\n",
      "You MUST suggest actual places to visit, actual hotels \n",
      "to stay and actual restaurants to go to.\n",
      "\n",
      "Trip Date: January 2025\n",
      "Traveling from: SF\n",
      "Traveling to: Paris\n",
      "Traveler Interests: art\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAmazing Travel Concierge\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "# **7-Day Travel Itinerary for Art Lovers in Paris (January 2025)**\n",
      "\n",
      "## **Overview**\n",
      "Prepare for a week of artistic indulgence in the City of Light! Experience world-class museums, vibrant neighborhoods, and culinary delights, all set against the backdrop of Paris's winter beauty.\n",
      "\n",
      "### **Weather Forecast for January**\n",
      "- Average temperatures: 3-7°C (37-45°F)\n",
      "- Expected precipitation: Light rain possible\n",
      "- **Packing Suggestions**: \n",
      "  - Warm layers: sweaters, long-sleeve shirts, and thermal underwear\n",
      "  - Waterproof jacket and umbrella\n",
      "  - Comfortable walking shoes\n",
      "  - Scarf, gloves, and a hat for added warmth\n",
      "  - Art journal or sketchbook for impromptu doodles\n",
      "\n",
      "### **Budget Overview**\n",
      "- **Flights**: ~$700 roundtrip from SF to Paris (booked in advance)\n",
      "- **Accommodation**: ~$180 per night for 6 nights → $1,080\n",
      "- **Daily Expenses**:\n",
      "  - Food: ~$50/day → $350 for 7 days\n",
      "  - Transport (Navigo pass): ~$30\n",
      "  - Museum entry fees: ~$50\n",
      "  - Miscellaneous (shopping, snacks): ~$100\n",
      "- **Total Estimated Budget**: ~$2,410\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 1: Arrival in Paris**\n",
      "- **Morning**: Flight from San Francisco → Arrive in Paris (CDG Airport).\n",
      "- **Afternoon**: Check-in at **Hôtel des Arts Montmartre**. Cozy and artistic, this hotel is located near artists' haunts.\n",
      "- **Evening**: Stroll through Montmartre; enjoy dinner at **Le Consulat**, a charming, historic bistro.\n",
      "- **Rest**: Unwind after travel; adjust to the time zone.\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 2: Louvre Museum & Seine River Walk**\n",
      "- **Morning**: Visit the **Louvre Museum** (book tickets online for 9 AM entry). Marvel at world-renowned art, including the \"Mona Lisa.\"\n",
      "- **Lunch**: **Cafe Marly** – stunning views of the Louvre’s glass pyramid.\n",
      "- **Afternoon**: Walk along the Seine River; stop at **Pont des Arts** for gorgeous photos.\n",
      "- **Evening**: Dinner at **Le Fumoir** near the Louvre, a classic spot with a vintage vibe.\n",
      "- **Night**: Relax at your hotel or explore Montmartre's nightlife.\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 3: Musée d'Orsay & Le Marais**\n",
      "- **Morning**: Head to the **Musée d'Orsay** (10 AM). Explore Impressionist masterpieces.\n",
      "- **Lunch**: **Restaurant de l'Opéra** inside the museum for a delightful meal.\n",
      "- **Afternoon**: Walk to **Le Marais**; explore galleries and unique boutiques. Visit the **Picasso Museum**.\n",
      "- **Evening**: Dinner at **Chez Janou**, known for its traditional Provençal cuisine and lovely courtyard.\n",
      "  \n",
      "---\n",
      "\n",
      "## **Day 4: Centre Pompidou & Local Markets**\n",
      "- **Morning**: Visit the **Centre Pompidou** (10 AM), admire its contemporary art collection, and get stunning views from the rooftop.\n",
      "- **Lunch**: **Le Georges** at the Center for a stylish experience.\n",
      "- **Afternoon**: Explore the nearby **Les Halles** area and enjoy the local market vibes at **Rue Montorgueil**.\n",
      "- **Evening**: Dinner at **L'Escargot Montorgueil**, famous for its escargots.\n",
      "  \n",
      "---\n",
      "\n",
      "## **Day 5: Hidden Gems - Musée de la Vie Romantique & Atelier des Lumières**\n",
      "- **Morning**: Discover the **Musée de la Vie Romantique**. The charming museum is free and surrounded by a lovely garden.\n",
      "- **Lunch**: **Cafe de la Vie Romantique**, perfect for a light lunch in the garden’s peaceful atmosphere.\n",
      "- **Afternoon**: Visit the **Atelier des Lumières** for an immersive digital art experience. Make sure to pre-book tickets!\n",
      "- **Evening**: Return to Montmartre for dinner at **La Palette**, favored by many artists, with a charming ambience.\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 6: Musée Gustave Moreau & Montparnasse**\n",
      "- **Morning**: Visit the **Musée Gustave Moreau**. Explore the studio of the symbolist painter.\n",
      "- **Lunch**: **Le Dôme Café** in Montparnasse, a historic brasserie famous for seafood.\n",
      "- **Afternoon**: Explore Montparnasse and perhaps visit the **Fondation Cartier** for contemporary art.\n",
      "- **Evening**: Enjoy a classic dining experience at **La Coupole**, another historic venue.\n",
      "  \n",
      "---\n",
      "\n",
      "## **Day 7: Departure**\n",
      "- **Morning**: Last-minute shopping in **Saint-Germain-des-Prés**; visit **Café de Flore** for breakfast.\n",
      "- **Afternoon**: Check out of your hotel; transfer to the airport for your flight back to San Francisco.\n",
      "  \n",
      "### **Additional Tips**\n",
      "- **Language**: Basic French phrases can enhance your experience; familiarize yourself with key greetings and thanks.\n",
      "- **Cultural Respect**: Always greet in French (\"Bonjour\") before asking for help.\n",
      "  \n",
      "Enjoy your captivating journey filled with culture, creativity, and the undeniable magic of Paris! Your art-filled adventure awaits!\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_crew = TripCrew('SF', \"Paris\", 'January 2025', 'art')\n",
    "result = trip_crew.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyfyYvi7PyPk",
    "outputId": "44944593-ad50-4372-c966-422a1fb599d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# **7-Day Travel Itinerary for Art Lovers in Paris (January 2025)**\n",
      "\n",
      "## **Overview**\n",
      "Prepare for a week of artistic indulgence in the City of Light! Experience world-class museums, vibrant neighborhoods, and culinary delights, all set against the backdrop of Paris's winter beauty.\n",
      "\n",
      "### **Weather Forecast for January**\n",
      "- Average temperatures: 3-7°C (37-45°F)\n",
      "- Expected precipitation: Light rain possible\n",
      "- **Packing Suggestions**: \n",
      "  - Warm layers: sweaters, long-sleeve shirts, and thermal underwear\n",
      "  - Waterproof jacket and umbrella\n",
      "  - Comfortable walking shoes\n",
      "  - Scarf, gloves, and a hat for added warmth\n",
      "  - Art journal or sketchbook for impromptu doodles\n",
      "\n",
      "### **Budget Overview**\n",
      "- **Flights**: ~$700 roundtrip from SF to Paris (booked in advance)\n",
      "- **Accommodation**: ~$180 per night for 6 nights → $1,080\n",
      "- **Daily Expenses**:\n",
      "  - Food: ~$50/day → $350 for 7 days\n",
      "  - Transport (Navigo pass): ~$30\n",
      "  - Museum entry fees: ~$50\n",
      "  - Miscellaneous (shopping, snacks): ~$100\n",
      "- **Total Estimated Budget**: ~$2,410\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 1: Arrival in Paris**\n",
      "- **Morning**: Flight from San Francisco → Arrive in Paris (CDG Airport).\n",
      "- **Afternoon**: Check-in at **Hôtel des Arts Montmartre**. Cozy and artistic, this hotel is located near artists' haunts.\n",
      "- **Evening**: Stroll through Montmartre; enjoy dinner at **Le Consulat**, a charming, historic bistro.\n",
      "- **Rest**: Unwind after travel; adjust to the time zone.\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 2: Louvre Museum & Seine River Walk**\n",
      "- **Morning**: Visit the **Louvre Museum** (book tickets online for 9 AM entry). Marvel at world-renowned art, including the \"Mona Lisa.\"\n",
      "- **Lunch**: **Cafe Marly** – stunning views of the Louvre’s glass pyramid.\n",
      "- **Afternoon**: Walk along the Seine River; stop at **Pont des Arts** for gorgeous photos.\n",
      "- **Evening**: Dinner at **Le Fumoir** near the Louvre, a classic spot with a vintage vibe.\n",
      "- **Night**: Relax at your hotel or explore Montmartre's nightlife.\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 3: Musée d'Orsay & Le Marais**\n",
      "- **Morning**: Head to the **Musée d'Orsay** (10 AM). Explore Impressionist masterpieces.\n",
      "- **Lunch**: **Restaurant de l'Opéra** inside the museum for a delightful meal.\n",
      "- **Afternoon**: Walk to **Le Marais**; explore galleries and unique boutiques. Visit the **Picasso Museum**.\n",
      "- **Evening**: Dinner at **Chez Janou**, known for its traditional Provençal cuisine and lovely courtyard.\n",
      "  \n",
      "---\n",
      "\n",
      "## **Day 4: Centre Pompidou & Local Markets**\n",
      "- **Morning**: Visit the **Centre Pompidou** (10 AM), admire its contemporary art collection, and get stunning views from the rooftop.\n",
      "- **Lunch**: **Le Georges** at the Center for a stylish experience.\n",
      "- **Afternoon**: Explore the nearby **Les Halles** area and enjoy the local market vibes at **Rue Montorgueil**.\n",
      "- **Evening**: Dinner at **L'Escargot Montorgueil**, famous for its escargots.\n",
      "  \n",
      "---\n",
      "\n",
      "## **Day 5: Hidden Gems - Musée de la Vie Romantique & Atelier des Lumières**\n",
      "- **Morning**: Discover the **Musée de la Vie Romantique**. The charming museum is free and surrounded by a lovely garden.\n",
      "- **Lunch**: **Cafe de la Vie Romantique**, perfect for a light lunch in the garden’s peaceful atmosphere.\n",
      "- **Afternoon**: Visit the **Atelier des Lumières** for an immersive digital art experience. Make sure to pre-book tickets!\n",
      "- **Evening**: Return to Montmartre for dinner at **La Palette**, favored by many artists, with a charming ambience.\n",
      "\n",
      "---\n",
      "\n",
      "## **Day 6: Musée Gustave Moreau & Montparnasse**\n",
      "- **Morning**: Visit the **Musée Gustave Moreau**. Explore the studio of the symbolist painter.\n",
      "- **Lunch**: **Le Dôme Café** in Montparnasse, a historic brasserie famous for seafood.\n",
      "- **Afternoon**: Explore Montparnasse and perhaps visit the **Fondation Cartier** for contemporary art.\n",
      "- **Evening**: Enjoy a classic dining experience at **La Coupole**, another historic venue.\n",
      "  \n",
      "---\n",
      "\n",
      "## **Day 7: Departure**\n",
      "- **Morning**: Last-minute shopping in **Saint-Germain-des-Prés**; visit **Café de Flore** for breakfast.\n",
      "- **Afternoon**: Check out of your hotel; transfer to the airport for your flight back to San Francisco.\n",
      "  \n",
      "### **Additional Tips**\n",
      "- **Language**: Basic French phrases can enhance your experience; familiarize yourself with key greetings and thanks.\n",
      "- **Cultural Respect**: Always greet in French (\"Bonjour\") before asking for help.\n",
      "  \n",
      "Enjoy your captivating journey filled with culture, creativity, and the undeniable magic of Paris! Your art-filled adventure awaits!\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "aeNdhcPWMr-J",
    "outputId": "d9ff3b28-077f-4dc3-85a5-e0b59d6794b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Welcome to Trip Planner Crew\n",
      "-——————————\n",
      "\n",
      "From where will you be traveling from?\n",
      "sf\n",
      "\n",
      "What are the cities options you are interested in visiting?\n",
      "paris\n",
      "\n",
      "What is the date range you are interested in traveling?\n",
      "january\n",
      "\n",
      "What are some of your high level interests and hobbies?\n",
      "art\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TripTasks.gather_task() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ffedc08755b6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mtrip_crew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripCrew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrip_crew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n########################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## Here is you Trip Plan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-33ad35fd2442>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     gather_task = tasks.gather_task(\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_expert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: TripTasks.gather_task() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  print(\"## Welcome to Trip Planner Crew\")\n",
    "  print('-——————————')\n",
    "  location = input(\n",
    "    dedent(\"\"\"\n",
    "      From where will you be traveling from?\n",
    "    \"\"\"))\n",
    "  city = input(\n",
    "    dedent(\"\"\"\n",
    "      Where do you want to go?\n",
    "    \"\"\"))\n",
    "  date_range = input(\n",
    "    dedent(\"\"\"\n",
    "      What is the date range you are interested in traveling?\n",
    "    \"\"\"))\n",
    "  interests = input(\n",
    "    dedent(\"\"\"\n",
    "      What are some of your high level interests and hobbies?\n",
    "    \"\"\"))\n",
    "\n",
    "  trip_crew = TripCrew(location, city, date_range, interests)\n",
    "  result = trip_crew.run()\n",
    "  print(\"\\n\\n########################\")\n",
    "  print(\"## Here is you Trip Plan\")\n",
    "  print(\"########################\\n\")\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw0yL9U3Mtmp"
   },
   "outputs": [],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
